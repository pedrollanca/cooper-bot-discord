# Discord AI Assistant Bot

A small, local-first Discord bot that replies to mentions with text generated by a local LLM API. The bot's behavior is controlled by a plain-text system prompt and runtime configuration via environment variables.

Purpose
-------
Provide an on-premise AI assistant that can be dropped into a Discord server and respond to user mentions with configurable personality and safety constraints. The design prioritizes simplicity, testability, and the ability to use local LLM endpoints.

Technical summary
-----------------
- Language: Python (asyncio)
- Discord integration: discord.py
- HTTP client: aiohttp (async)
- Configuration: environment variables + system prompt file
- SSL: system certificates via certifi
- Tests: unittest with async support; test runner included

Repository layout
-----------------
- my_discord_ai_bot.py     — main bot implementation and event handlers
- system_prompt.txt        — system prompt that shapes the bot's responses
- system_prompt_demo.txt   — example prompt template
- .env.example             — environment variable template
- requirements.txt         — Python dependencies
- test_my_discord_ai_bot.py— unit tests covering core functionality
- test_runner.py           — async-aware test runner

Quick start
-----------
1. Create and activate a Python virtual environment:
   - Linux / macOS:
     python -m venv venv
     source venv/bin/activate
   - Windows (PowerShell):
     python -m venv venv
     .\venv\Scripts\Activate.ps1

2. Install dependencies:
   pip install -r requirements.txt

3. Configure environment:
   Copy `.env.example` to `.env` and set the required values:
   - DISCORD_TOKEN: Discord bot token (required)
   - BOT_NAME: optional friendly name used in logs and messages
   - OLLAMA_URL: local LLM API endpoint (default in example)
   - MODEL, TEMPERATURE, MAX_TOKENS: model parameters

4. Edit system prompt:
   Update `system_prompt.txt` to define the bot's personality, safety constraints, and reply style.

5. Start the bot:
   python my_discord_ai_bot.py

How it works
------------
- The bot listens for messages and only acts when it is mentioned.
- On mention, the bot removes mention tokens, prepares a payload with the system prompt and user content, and sends it to the configured LLM API.
- The API response is trimmed to a configurable maximum length and sent back as a reply.
- Secure HTTP connections use the system certificate bundle via certifi.

Configuration details
---------------------
Key environment variables (from `.env.example`):
- DISCORD_TOKEN — required bot token
- BOT_NAME — optional display name in logs
- OLLAMA_URL — LLM API URL (defaults to a local Ollama-style endpoint)
- MODEL — model identifier passed to the LLM API
- TEMPERATURE — sampling temperature for generation
- MAX_TOKENS — max tokens for the LLM request

Testing
-------
- Run the provided async-aware test runner:
  python test_runner.py

- Tests cover:
  - system prompt loading and fallback
  - mention parsing and message processing
  - LLM request/response handling (using mocked aiohttp)
  - configuration and SSL context validation

Troubleshooting
---------------
- Bot fails to start: ensure `DISCORD_TOKEN` is present in `.env` and valid.
- LLM API errors: verify `OLLAMA_URL` is reachable and responds with the expected JSON structure.
- System prompt missing/empty: `system_prompt.txt` must contain the instructions that shape responses; a fallback message exists but is not recommended for production.
- Dependency issues: confirm the virtual environment is active and `pip install -r requirements.txt` completed successfully.

Extending the project
---------------------
- Add new discord.py commands or event handlers for richer interactions.
- Replace or extend the LLM integration to support streaming, alternate endpoints, or additional metadata.
- Introduce moderation or more advanced safety-filtering layers before sending replies.

Contribution and license
------------------------
Contributions are welcome. Follow standard Git workflows: branch, test, and open pull requests. See the LICENSE file for licensing details.
